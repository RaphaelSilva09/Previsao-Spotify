{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Predição de Sucessos Spotify\n",
    "\n",
    "Esse projeto tem como finalidade o desenvolvimento de um modelo preditivo capaz de analisar músicas do aplicativo e determinar se elas vão ser bem-sucedidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos instalar e importar as bibliotecas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy seaborn scikit-learn matplotlib tabulate\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay # type: ignore\n",
    "from sklearn.ensemble import RandomForestClassifier # type: ignore\n",
    "from sklearn.preprocessing import LabelEncoder # type: ignore\n",
    "from sklearn.model_selection import RandomizedSearchCV # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois vamos abrir os arquivos que iremos usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploração dos dados\n",
    "\n",
    "Nesse momento, faremos uma análise dos dados para determinar se existem problemas na base de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### identificação de duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates based on 'track_id' and 'track_name'\n",
    "duplicate_rows = df_train[df_train.duplicated(subset=['track_id', 'track_name'])]\n",
    "duplicate_count = duplicate_rows.shape[0]\n",
    "\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "# Display the duplicates if found\n",
    "if duplicate_count > 0:\n",
    "    display(duplicate_rows.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identificação de outliers\n",
    "\n",
    "Ao utilizar os gráficos boxplot abaixo, somos capazes de visualizar como os valores se comportam nos casos de músicas bem-sucedidas e no geral, criando uma visualização das relações desejadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset for only successful songs (popularity_target == 1)\n",
    "successful_songs = df_train[df_train['popularity_target'] == 1]\n",
    "\n",
    "# Define the numeric columns\n",
    "numeric_columns = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                   'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "\n",
    "# Plot side-by-side boxplots for all songs and successful songs\n",
    "plt.figure(figsize=(15, 30))  # Adjust the size to accommodate the double plots\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    # Boxplot for all songs (left)\n",
    "    plt.subplot(len(numeric_columns), 2, 2 * i + 1)\n",
    "    sns.boxplot(x=df_train[col])\n",
    "    plt.title(f\"Boxplot of {col} (All Songs)\")\n",
    "\n",
    "    # Boxplot for successful songs (right)\n",
    "    plt.subplot(len(numeric_columns), 2, 2 * i + 2)\n",
    "    sns.boxplot(x=successful_songs[col])\n",
    "    plt.title(f\"Boxplot of {col} (Successful Songs)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificação da quantidade de músicas de sucesso para os top 20 gêneros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por gênero e status de sucesso\n",
    "genre_grouped = df_train.groupby(['track_genre', 'popularity_target']).size().unstack().fillna(0)\n",
    "\n",
    "# Pegar os top 20 gêneros com mais músicas\n",
    "top_genres = genre_grouped.sum(axis=1).sort_values(ascending=False).head(20).index\n",
    "\n",
    "# Filtrar o DataFrame pelos top 20 gêneros\n",
    "top_genre_grouped = genre_grouped.loc[top_genres]\n",
    "\n",
    "# Plotar gráfico de barras com os top 20 gêneros\n",
    "plt.figure(figsize=(14, 8))\n",
    "top_genre_grouped.plot(kind='bar', figsize=(14, 8), width=0.7, edgecolor='black')\n",
    "\n",
    "# Adicionar título e rótulos\n",
    "plt.title('Top 20 Gêneros com Mais Músicas: Sucesso vs Não Sucesso', fontsize=18)\n",
    "plt.xlabel('Gênero', fontsize=14)\n",
    "plt.ylabel('Quantidade de Músicas', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(title='Sucesso', labels=['Não Sucesso', 'Sucesso'], fontsize=12, title_fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de Hipóteses\n",
    "\n",
    "Ao analisar o gráfico acima, podemos criar algumas hipóteses sobre os dados:\n",
    "\n",
    "- Quanto mais vocal e menos acústica a música, maior a proporção de sucessos para fracassos.\n",
    "- Músicas com energia média-alta tendem a ser bem sucedidas.\n",
    "- Se a música estiver localizada com intensidade entre -10 e 0 fazem sucesso.\n",
    "- Os top 5 gêneros de maior sucesso são \"gospel\", \"sad\", \"forro\", \"turkish\", \"mpb\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos dados\n",
    "\n",
    "A fim de manter a o comportamento dos dados das músicas de sucesso, realizei uma remoção de outliers com base na análise dos resultados de sucesso, por meio da função abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_based_on_success(df, success_df, columns):\n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        # Calcular o IQR das músicas de sucesso\n",
    "        Q1_success = success_df[col].quantile(0.25)\n",
    "        Q3_success = success_df[col].quantile(0.75)\n",
    "        IQR_success = Q3_success - Q1_success\n",
    "        \n",
    "        # Definir limites com base no IQR das músicas de sucesso\n",
    "        lower_bound = Q1_success - 1.5 * IQR_success\n",
    "        upper_bound = Q3_success + 1.5 * IQR_success\n",
    "        \n",
    "        # Filtrar os dados mantendo apenas valores dentro dos limites\n",
    "        df_filtered = df_filtered[(df_filtered[col] >= lower_bound) & (df_filtered[col] <= upper_bound)]\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Aplicar a função para remover outliers baseando-se no intervalo das músicas de sucesso\n",
    "df_filtered_for_training = remove_outliers_based_on_success(df_train, successful_songs, numeric_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, a fim de manter os mesmo valores para as mesmas categorias, concatenei os df_train e df_test, para passá-los pelo labelEncoder e pelo drop das colunas inúteis (para predição) sem risco de erros. Depois separo os dataframes para seguir com o processo previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar os DataFrames\n",
    "df_combined = pd.concat([df_filtered_for_training, df_test], ignore_index=True, axis=0)\n",
    "\n",
    "# Dropar colunas irrelevantes\n",
    "irrelevant_columns = ['track_id', 'track_name']\n",
    "df_filtered_for_training = df_combined.drop(columns=irrelevant_columns)\n",
    "\n",
    "# Identificar colunas categóricas\n",
    "categorical_columns = ['track_unique_id', 'artists', 'album_name', 'explicit', 'key', 'mode', 'track_genre']\n",
    "\n",
    "# Aplicar Label Encoding nas colunas categóricas\n",
    "for col in categorical_columns:\n",
    "    df_filtered_for_training[col] = LabelEncoder().fit_transform(df_filtered_for_training[col])\n",
    "    \n",
    "# Separar os DataFrames novamente\n",
    "df_train_encoded = df_filtered_for_training.iloc[:43286].reset_index(drop=True)\n",
    "df_test_encoded = df_filtered_for_training.iloc[43286:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação e treinamento do modelo\n",
    "\n",
    "Nessa etapa, separamos dados de treino e teste usando *train_test_spliter* e fazendo o treinamento com Random Forest Classifier, medindo sua acurácia e demonstrando isso por meio de uma matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as variáveis independentes (X) e dependente (y)\n",
    "X = df_train_encoded.drop(columns=['popularity_target'])\n",
    "y = df_train_encoded['popularity_target']\n",
    "\n",
    "# Dividir os dados em treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir o modelo Random Forest\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Medição da acurácia do modelo\n",
    "accuracy = accuracy_score(np.round(y_test), np.round(y_pred))\n",
    "print(f\"Acurácia do modelo de Random Forest: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação dos Resultados\n",
    "\n",
    "Podemos visualizar a eficiência do modelo por meio de uma matriz de confusão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar a matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Criar a visualização da matriz de confusão\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(cm, cmap='Blues', annot=True, fmt='d', cbar=False)\n",
    "\n",
    "# Configurar os rótulos e títulos\n",
    "plt.title('Quantidade de Músicas por Gênero: Sucesso vs Não Sucesso')\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Valor Verdadeiro')\n",
    "\n",
    "# Definir os rótulos das categorias (opcional, substitua conforme necessário)\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['Não Sucesso', 'Sucesso'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['Não Sucesso', 'Sucesso'])\n",
    "\n",
    "# Exibir a matriz de confusão\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunning e Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os hiperparâmetros a serem testados\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400], # Número de árvores na floresta\n",
    "    'max_depth': [10, 20, 30, 40, None], # Profundidade máxima de cada árvore\n",
    "    'min_samples_split': [2, 5], # Número mínimo de amostras necessárias para dividir um nó\n",
    "    'min_samples_leaf': [1, 2, 4], # Número mínimo de amostras necessárias em uma folha\n",
    "    'max_features': ['log2', 'sqrt'], # Número de recursos a serem considerados para a melhor divisão\n",
    "    'bootstrap': [True, False] # Se deve usar amostragem com reposição\n",
    "}\n",
    "\n",
    "# Configurar o Grid Search com validação cruzada\n",
    "grid_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, \n",
    "                           cv=10, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Executar o Grid Search no conjunto de treino\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibir os melhores hiperparâmetros encontrados\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Treinar o modelo com os melhores hiperparâmetros encontrados\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_best_model = best_model.predict(X_test)\n",
    "\n",
    "# Avaliar a acurácia do modelo com os melhores hiperparâmetros\n",
    "accuracy = accuracy_score(y_test, y_pred_best_model)\n",
    "print(f\"Acurácia do modelo otimizado: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nova Avaliação do modelo\n",
    "\n",
    "Por fim vamos recriar as matrizes de confusão do modelo inicial e do modelo com *tunnings*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular as matrizes de confusão\n",
    "cm_old = confusion_matrix(y_test, y_pred)\n",
    "cm_new = confusion_matrix(y_test, y_pred_best_model)\n",
    "\n",
    "# Criar as figuras para as matrizes de confusão\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Exibir a matriz de confusão do modelo antigo\n",
    "disp_old = ConfusionMatrixDisplay(confusion_matrix=cm_old, display_labels=['Não Sucesso', 'Sucesso'])\n",
    "disp_old.plot(ax=ax[0], cmap=plt.cm.Blues)\n",
    "ax[0].set_title('Matriz de Confusão - Modelo Antigo')\n",
    "\n",
    "# Exibir a matriz de confusão do modelo otimizado\n",
    "disp_new = ConfusionMatrixDisplay(confusion_matrix=cm_new, display_labels=['Não Sucesso', 'Sucesso'])\n",
    "disp_new.plot(ax=ax[1], cmap=plt.cm.Blues)\n",
    "ax[1].set_title('Matriz de Confusão - Modelo Otimizado')\n",
    "\n",
    "# Exibir as matrizes de confusão\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envio dos resultados\n",
    "\n",
    "Por fim, basta que importemos o resultado final para avaliação no Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test_encoded.drop(columns=['popularity_target'])\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "# Salvar os valores preditos em um dataframe\n",
    "resultados = pd.DataFrame({\n",
    "    'track_unique_id': df_test['track_unique_id'],\n",
    "    'popularity_prediction': y_pred2\n",
    "})\n",
    "\n",
    "# Salvar as previsões em um arquivo CSV\n",
    "resultados.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
